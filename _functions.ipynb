{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902abbc6-f352-48ec-afad-64291f91a0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arange(\n",
    "        arg1: float,\n",
    "        arg2: float or None = None,\n",
    "        arg3: float or None = None,\n",
    "        arg4: bool or None = None):\n",
    "    \n",
    "    '''\n",
    "    Realization of simple range (based on np.arange) with protection from \n",
    "    float large decimals, e.g. 1.100000000009 except 1.1)\n",
    "    \n",
    "    default:\n",
    "        arg1 - start\n",
    "        arg2 - stop\n",
    "        arg3 - step\n",
    "        arg4 - endpoint (if True: 'stop' value included in range; if False: 'stop' value not included in range)\n",
    "\n",
    "    variations:\n",
    "        arange(arg1) -> range(start=0, stop=arg1, step=1, endpoint=False)\n",
    "        \n",
    "        arange(arg1, arg2):\n",
    "            arange(float, float) -> (start=arg1, stop=arg2, step=1, endpoint=False)\n",
    "            arange(float, bool) -> range(start=0, stop=arg1, step=1, endpoint=arg2)\n",
    "            \n",
    "            \n",
    "        arange(arg1, arg2, arg3):\n",
    "            arange(float, float, float) -> (start=arg1, stop=arg2, step=arg3, endpoint=False)\n",
    "            arange(float, float, bool) -> range(start=arg1, stop=arg2, step=1, endpoint=arg3)\n",
    "            \n",
    "        arange(arg1, arg2, arg3, arg4):\n",
    "            arange(float, float, float, bool) -> range(start=arg1, stop=arg2, step=arg3, endpoint=arg4)\n",
    "\n",
    "    dependencies:\n",
    "        libraries: numpy, decimal, numbers\n",
    "    '''\n",
    "\n",
    "    # list of argument values\n",
    "    arg_values = locals().values()\n",
    "\n",
    "    # create list with decimals of arguments values\n",
    "    round_idxs = []\n",
    "    for i in arg_values:\n",
    "        if (isinstance(i, numbers.Number) and not\n",
    "            isinstance(i, bool)):\n",
    "            decimals = decimal.Decimal(str(i)).as_tuple().exponent\n",
    "            round_idxs.append(abs(decimals))\n",
    "    # find maximum number of decimals - \n",
    "    # all values would be round to it later to avoid X.XXXXXXXXXX float\n",
    "    round_dec = max(round_idxs)\n",
    "    \n",
    "    # True/False marker if result should be all integers\n",
    "    is_int = False\n",
    "\n",
    "    # if only one argument: arange(arg1)\n",
    "    if ((arg1 is not None) & (arg2 is None) &\n",
    "        (arg3 is None) & (arg4 is None)):\n",
    "        # equivalent (start=0, stop=arg1, step=1, endpoint=False)\n",
    "        start = 0\n",
    "        stop = arg1\n",
    "        # return empty array if start and stop equals\n",
    "        if start == stop:\n",
    "            arr = np.empty(0)\n",
    "            return arr\n",
    "        step = 1\n",
    "        endpoint = False\n",
    "        # rememeber decimal number of stop variable\n",
    "        round_dec_for_stop = decimal.Decimal(str(stop)).as_tuple()\n",
    "        round_dec_for_stop = abs(round_dec_for_stop.exponent)\n",
    "        \n",
    "        if isinstance(arg1, int):\n",
    "            is_int = True\n",
    "\n",
    "    # if two arguments: arange(arg1, arg2)\n",
    "    if ((arg1 is not None) & (arg2 is not None) &\n",
    "        (arg3 is None) & (arg4 is None)):\n",
    "        \n",
    "        # if second argument boolean: arange(number1, True)\n",
    "        if isinstance(arg2, bool):\n",
    "            # equivalent (start=0, stop=arg1, step=1, endpoint=arg2)\n",
    "            start = 0\n",
    "            stop = arg1\n",
    "            step = 1\n",
    "            endpoint = arg2\n",
    "            # rememeber decimal number of stop variable\n",
    "            round_dec_for_stop = decimal.Decimal(str(stop)).as_tuple()\n",
    "            round_dec_for_stop = abs(round_dec_for_stop.exponent)\n",
    "        # if second argument not boolean: arange(number1, number2)\n",
    "        else:\n",
    "            # equivalent (start=arg1, stop=arg2, step=1, endpoint=False)\n",
    "            start = arg1\n",
    "            stop = arg2\n",
    "            # return empty array if start and stop equals\n",
    "            if start == stop:\n",
    "                arr = np.empty(0)\n",
    "                return arr\n",
    "            step = 1\n",
    "            endpoint = False\n",
    "            # rememeber decimal number of stop variable\n",
    "            round_dec_for_stop = decimal.Decimal(str(stop)).as_tuple()\n",
    "            round_dec_for_stop = abs(round_dec_for_stop.exponent)\n",
    "\n",
    "        if isinstance(arg1, int) & isinstance(arg2, int):\n",
    "            is_int = True\n",
    "\n",
    "    # if three arguments: arange(arg1, arg2, arg3)\n",
    "    if ((arg1 is not None) & (arg2 is not None) &\n",
    "        (arg3 is not None) & (arg4 is None)):\n",
    "        # if third argument boolean: arange(number1, number2, True)\n",
    "        if isinstance(arg3, bool):\n",
    "            # equivalent (start=arg1, stop=arg2, step=1, endpoint=arg3)\n",
    "            start = arg1\n",
    "            stop = arg2\n",
    "            # return empty array if start and stop equals\n",
    "            if start == stop:\n",
    "                arr = np.empty(0)\n",
    "                return arr\n",
    "            step = 1\n",
    "            endpoint = arg3\n",
    "            # rememeber decimal number of stop variable\n",
    "            round_dec_for_stop = decimal.Decimal(str(stop)).as_tuple()\n",
    "            round_dec_for_stop = abs(round_dec_for_stop.exponent)\n",
    "        # if third argument not boolean: arange(number1, number2, number3)\n",
    "        else:\n",
    "            # equivalent (start=arg1, stop=arg2, step=arg3, endpoint=False)\n",
    "            start = arg1\n",
    "            stop = arg2\n",
    "            # return empty array if start and stop equals\n",
    "            if start == stop:\n",
    "                arr = np.empty(0)\n",
    "                return arr\n",
    "            step = arg3\n",
    "            endpoint = False\n",
    "            # rememeber decimal number of stop variable\n",
    "            round_dec_for_stop = decimal.Decimal(str(stop)).as_tuple()\n",
    "            round_dec_for_stop = abs(round_dec_for_stop.exponent)\n",
    "\n",
    "        if (isinstance(arg1, int) & isinstance(arg2, int) &\n",
    "               isinstance(arg3, int)):\n",
    "            is_int = True\n",
    "\n",
    "    # if all arguments: arange(arg1, arg2, arg4, True)\n",
    "    if ((arg1 is not None) & (arg2 is not None) &\n",
    "        (arg3 is not None) & (arg4 is not None)):\n",
    "        # equivalent (start=arg1, stop=arg2, step=arg3, endpoint=arg4)\n",
    "        start = arg1\n",
    "        stop = arg2\n",
    "        # return empty array if start and stop equals\n",
    "        if start == stop:\n",
    "            arr = np.empty(0)\n",
    "            return arr\n",
    "        step = arg3\n",
    "        endpoint = arg4\n",
    "        # rememeber decimal number of stop variable\n",
    "        round_dec_for_stop = decimal.Decimal(str(stop)).as_tuple()\n",
    "        round_dec_for_stop = abs(round_dec_for_stop.exponent)\n",
    "\n",
    "        if (isinstance(arg1, int) & isinstance(arg2, int) &\n",
    "            isinstance(arg3, int)):\n",
    "            is_int = True\n",
    "\n",
    "    # arr = step * np.arange(start/step, stop/step)\n",
    "    arr = np.arange(start, stop, step)\n",
    "    # round array to avoid X.XXXXXXXXXXXX float\n",
    "    arr = np.around(arr, decimals=round_dec)\n",
    "    # if last value of arr plus step equals to stop it concatenates to arr\n",
    "    last_value = arr[-1]\n",
    "    # also round this value to avoid X.XXXXXXXXXXXX float (number decimals as in stop variable)\n",
    "    last_value_plus_step = np.around(last_value+step, round_dec_for_stop)\n",
    "    if endpoint and last_value_plus_step==stop:\n",
    "        arr = np.concatenate([arr,[stop]])\n",
    "    if is_int:\n",
    "        arr = np.around(arr, decimals=0)\n",
    "        arr = arr.astype(int)\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cdc0c8-f55c-436a-a66f-d76572ba1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth data\n",
    "\n",
    "def smoothed(x, y=None, n=300, k=3, return_type='df', datetime_index=False):\n",
    "    '''\n",
    "    Smooth data for plots\n",
    "    \n",
    "    Arguments:\n",
    "    x: pd.DataFrame, pd.Series\n",
    "    y: array-type\n",
    "    n: length of linespace\n",
    "    k: smoothing scale\n",
    "    return_type: \n",
    "        - if 'array' - return x_new, y_new\n",
    "        - if 'dict' - returns dict with {'x': x_new, 'y': y_new}\n",
    "\n",
    "    If x == pd.DataFrame functon returns pd.DataFrame anyway\n",
    "\n",
    "    Libraries:\n",
    "    from scipy.interpolate import make_interp_spline, BSpline\n",
    "    '''\n",
    "\n",
    "    if datetime_index:\n",
    "        start = x.index[0]\n",
    "        end = x.index[-1]\n",
    "        time_range = \\\n",
    "            pd.date_range(start=start, end=end, periods=n)\n",
    "        x = x.reset_index(drop=True)\n",
    "\n",
    "    if isinstance(x, pd.DataFrame):\n",
    "        var_name = x.columns[0] if x.columns[0] != 0 else 'variable'\n",
    "        x_index = x.index\n",
    "        x_new = np.linspace(x_index.min(), x_index.max(), n)\n",
    "        df = pd.DataFrame(index=x_new, columns=x.columns)\n",
    "        for col in x.columns:\n",
    "            y = x[col]\n",
    "            spl = scipy.interpolate.make_interp_spline(x_index, y, k=k)  # type: BSpline\n",
    "            y_new = spl(x_new)\n",
    "            df[col] = y_new\n",
    "        if return_type == 'df':\n",
    "            if datetime_index:\n",
    "                df.index = time_range\n",
    "            return df\n",
    "        if return_type == 'array':\n",
    "            return np.array(df.index), np.array(df.iloc[:, 0])\n",
    "        \n",
    "    elif isinstance(x, pd.Series):\n",
    "        var_name = x.name\n",
    "        y = x.copy()\n",
    "        x = x.index\n",
    "        \n",
    "        # n represents number of points to make between T.min and T.max\n",
    "        x_new = np.linspace(x.min(), x.max(), n) \n",
    "    \n",
    "        spl = scipy.interpolate.make_interp_spline(x, y, k=k)  # type: BSpline\n",
    "        y_new = spl(x_new)\n",
    "    \n",
    "        if return_type == 'dict':\n",
    "            if datetime_index:\n",
    "                ret_dict = {\n",
    "                    'x': time_range,\n",
    "                    'y': y_new\n",
    "                    }\n",
    "            else:\n",
    "                ret_dict = {\n",
    "                    'x': x_new,\n",
    "                    'y': y_new\n",
    "                    }\n",
    "            return ret_dict\n",
    "        elif return_type == 'array':\n",
    "            if datetime_index:\n",
    "                return time_range, y_new\n",
    "            else:\n",
    "                return x_new, y_new\n",
    "        elif return_type == 'df':\n",
    "            if datetime_index:\n",
    "                df = pd.DataFrame(data=y_new, index=time_range, columns=[var_name])\n",
    "            else:\n",
    "                df = pd.DataFrame(data=y_new, index=x_new, columns=[var_name])\n",
    "            return df\n",
    "    else:\n",
    "        y = x.copy()\n",
    "        x = arange(len(x))\n",
    "\n",
    "        # n represents number of points to make between T.min and T.max\n",
    "        x_new = np.linspace(x.min(), x.max(), n) \n",
    "    \n",
    "        spl = scipy.interpolate.make_interp_spline(x, y, k=k)  # type: BSpline\n",
    "        y_new = spl(x_new)\n",
    "        \n",
    "        if return_type == 'dict':\n",
    "            if datetime_index:\n",
    "                ret_dict = {\n",
    "                    'x': time_range,\n",
    "                    'y': y_new\n",
    "                    }\n",
    "            else:\n",
    "                ret_dict = {\n",
    "                    'x': x_new,\n",
    "                    'y': y_new\n",
    "                    }\n",
    "            return ret_dict\n",
    "        elif return_type == 'array':\n",
    "            if datetime_index:\n",
    "                return time_range, y_new\n",
    "            else:\n",
    "                return x_new, y_new\n",
    "        elif return_type == 'df':\n",
    "            if datetime_index:\n",
    "                df = pd.DataFrame(data=y_new, index=time_range, columns=['variable'])\n",
    "            else:\n",
    "                df = pd.DataFrame(data=y_new, index=x_new, columns=['variable'])\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d36e847-11ec-460f-bc87-b7059a31b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saturate and alpha colors\n",
    "\n",
    "def saturate_color(color_rgb, saturation=0.75):\n",
    "    color_hls = colorsys.rgb_to_hls(\n",
    "        color_rgb[0], color_rgb[1], color_rgb[2])\n",
    "    color_hls_saturated = (\n",
    "        color_hls[0], color_hls[1], saturation*color_hls[2])\n",
    "    color_rgb_saturated = colorsys.hls_to_rgb(\n",
    "        color_hls_saturated[0], color_hls_saturated[1], color_hls_saturated[2])\n",
    "    return color_rgb_saturated\n",
    "\n",
    "\n",
    "def alpha_color(color, alpha):\n",
    "    new_color = tuple (x + (1 - x) * (1 - alpha) for x in color)\n",
    "    return new_color\n",
    "\n",
    "\n",
    "def saturate_palette(palette, saturation=0.75):\n",
    "    palette_saturated = [saturate_color(i, saturation=saturation) for i in palette]\n",
    "    return palette_saturated\n",
    "\n",
    "\n",
    "def alpha_palette(palette, alpha=0.90):\n",
    "    palette_alphed = [alpha_color(i, alpha=alpha) for i in palette]\n",
    "    return palette_alphed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e3f05-4e45-4e05-95ae-67ba8c838f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are NaNs in df\n",
    "\n",
    "def is_nan(df):\n",
    "    ret = df[df.isna().any(axis=1)]\n",
    "    shape = df[df.isna().any(axis=1)].shape\n",
    "    if shape[0] > 0:\n",
    "        return ret\n",
    "    else:\n",
    "        print(\"No NaN values in DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0936e6df-c45d-4f51-a49a-9617c60555eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save-load\n",
    "\n",
    "def loadit(name, dir='files'):\n",
    "    result = pd.read_pickle(f'{dir}{name}.pkl')\n",
    "    return result\n",
    "\n",
    "def saveit(file, name, dir='files'):\n",
    "    # check if dir exists and create it if not\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "    # save file\n",
    "    filehandler = open(f'{dir}/{name}.pkl', 'wb') \n",
    "    pickle.dump(file, filehandler)\n",
    "    filehandler.close()\n",
    "    print(f\"File '{name}.pkl' saved in directory '{dir}'\")\n",
    "\n",
    "def savefig(name, dir='img', format='png', dpi=100, transparent=True,  figure=None, **kwargs):\n",
    "    '''\n",
    "    Saves figure as PNG to 'img/' dir\n",
    "    '''\n",
    "    if figure is None:\n",
    "       figure = fig\n",
    "    if dir is None:\n",
    "        dir = 'img'\n",
    "    else:\n",
    "        if dir != 'img':\n",
    "            dir = f'img/{dir}'\n",
    "        else:\n",
    "            pass\n",
    "    # check if dir exists and create it if not\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "    figure.savefig(\n",
    "        f'{dir}/{name}.{format}',\n",
    "        transparent=transparent,\n",
    "        bbox_inches='tight',\n",
    "        dpi=dpi, \n",
    "        format=format,\n",
    "        **kwargs\n",
    "    )\n",
    "    print(f\"Image '{name}.{format}' successfully saved into '{dir}' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e69162-437b-4836-9867-3f70ceeb3e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_bootstrap(\n",
    "        data, statistic=np.mean, n_bootstrap=1000,\n",
    "        confidence_level=0.95, random_state=42):\n",
    "    '''\n",
    "    Returns: dict(statistic, std, ci_min, ci_max, margin)\n",
    "    '''\n",
    "    data_ = (data,)\n",
    "    bootstrap = scipy.stats.bootstrap(\n",
    "        data=data_,\n",
    "        statistic=statistic,\n",
    "        n_resamples=n_bootstrap,\n",
    "        confidence_level=confidence_level,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    ci_min = bootstrap.confidence_interval[0]\n",
    "    ci_max = bootstrap.confidence_interval[1]\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        stat = data.apply(statistic)\n",
    "        stat = np.array(stat)\n",
    "        std = np.array(np.std(data, ddof=1))\n",
    "    else:\n",
    "        stat = statistic(data)\n",
    "        std = np.std(data, ddof=1)\n",
    "    margin = stat - ci_min\n",
    "\n",
    "    return_dct = {\n",
    "        'statistic': stat,\n",
    "        'std': std,\n",
    "        'ci_min': ci_min,\n",
    "        'ci_max': ci_max,\n",
    "        'margin': margin,\n",
    "    }\n",
    "    return return_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7c8a1-48ea-4fbb-b723-2386a7ad10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_t_distribution(\n",
    "        data=None, mean=None, std=None, n=None, confidence_level=0.95):\n",
    "\n",
    "    if data is not None:\n",
    "        arr = np.array(data)\n",
    "        n = len(arr)\n",
    "        mean = np.mean(arr)\n",
    "        se = scipy.stats.sem(arr)\n",
    "        \n",
    "    if mean and std and n is not None:\n",
    "        se = std / np.sqrt(n)\n",
    "\n",
    "    t = scipy.stats.t.ppf((1+confidence_level) / 2, n-1)\n",
    "    margin = t * se\n",
    "    ci_min = mean - margin\n",
    "    ci_max = mean + margin\n",
    "\n",
    "    return_dct = {\n",
    "        'min': ci_min,\n",
    "        'max': ci_max,\n",
    "        'mean': mean,\n",
    "        'margin': margin,\n",
    "        't': t\n",
    "    }\n",
    "    return return_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7273c22-4da3-404b-b606-437c7c77af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normality tests\n",
    "\n",
    "def test_normality(data, alpha=0.05):\n",
    "    \n",
    "    tests_names = []\n",
    "    pvalue = []\n",
    "    condition = []\n",
    "        \n",
    "    # Kolmogorov-Smirnov\n",
    "    ks = stats.kstest(data, 'norm')\n",
    "    pvalue_ks = ks.pvalue\n",
    "    tests_names.append('Kolmogorov-Smirnov')\n",
    "    pvalue.append(pvalue_ks)\n",
    "    if pvalue_ks < alpha:\n",
    "        condition.append('Not normal')\n",
    "    else:\n",
    "        condition.append('Normal')\n",
    "\n",
    "    # Anderson-Darling\n",
    "    and_dar = stats.anderson(data, dist='norm')\n",
    "    and_dar_sign = and_dar.critical_values[2]\n",
    "    and_dar_statistic = and_dar.statistic\n",
    "    tests_names.append('Anderson-Darling (s)')\n",
    "    pvalue.append(and_dar_statistic)\n",
    "    if and_dar_statistic > and_dar_sign:\n",
    "        condition.append('Not normal')\n",
    "    else:\n",
    "        condition.append('Normal')\n",
    "\n",
    "    # Shapiro-Wilk\n",
    "    pvalue_sw = stats.shapiro(data).pvalue\n",
    "    tests_names.append('Shapiro-Wilk')\n",
    "    pvalue.append(pvalue_sw)\n",
    "    if pvalue_sw < alpha:\n",
    "        condition.append('Not normal')\n",
    "    else:\n",
    "        condition.append('Normal')\n",
    "\n",
    "    # jarque-bera test\n",
    "    jb_name = [\"Jarque-Bera\", \"Chi^2\", \"Skew\", \"Kurtosis\"]\n",
    "    jb_statistic = sms.jarque_bera(data)\n",
    "    jb = dict(zip(jb_name, jb_statistic))\n",
    "    pvalue_jb = jb['Chi^2']\n",
    "    tests_names.append('Jarque-Bera')\n",
    "    pvalue.append(pvalue_jb)\n",
    "    if pvalue_jb < alpha:\n",
    "        condition.append('Not normal')\n",
    "    else:\n",
    "        condition.append('Normal')\n",
    "    \n",
    "    # D’Agostino and Pearson\n",
    "    dagp = stats.normaltest(data)\n",
    "    pvalue_dagp = dagp.pvalue\n",
    "    tests_names.append('D’Agostino-Pearson')\n",
    "    pvalue.append(pvalue_dagp)\n",
    "    if pvalue_dagp < alpha:\n",
    "        condition.append('Not normal')\n",
    "    else:\n",
    "        condition.append('Normal')\n",
    "\n",
    "    pvalue = [np.round(i, 4) for i in pvalue]\n",
    "    results_df = pd.DataFrame({\n",
    "        'Test': tests_names,\n",
    "        'P or Statistic (s)': pvalue,\n",
    "        'Condition': condition,\n",
    "    })\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da42dfc-90d4-4123-8691-791d874223a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_X_y(data, target):\n",
    "    '''\n",
    "    Move Target variable column to the end of DataFrame\n",
    "    '''\n",
    "    columns = data.columns.tolist()\n",
    "    columns.append(columns.pop(columns.index(target)))\n",
    "    df = data[columns].copy()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c0549c-22e6-470b-a1c8-a2908f6a7770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_display(\n",
    "        features, importance,\n",
    "        top=None, imp_min_level=None, only_features=True):\n",
    "\n",
    "    '''\n",
    "     \n",
    "    '''\n",
    "\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': importance\n",
    "    })\n",
    "    if imp_min_level is not None:\n",
    "        loc_row = feature_importance['Importance'] > imp_min_level\n",
    "        feature_importance = (feature_importance\n",
    "                              .loc[loc_row, :]\n",
    "                              .sort_values('Importance', ascending=False)\n",
    "                              .reset_index(drop=True))\n",
    "    if top is not None:\n",
    "        feature_importance = (feature_importance\n",
    "                             .sort_values('Importance', ascending=False)\n",
    "                             .reset_index(drop=True))\n",
    "        feature_importance = feature_importance.loc[0:top-1]\n",
    "\n",
    "    if only_features:\n",
    "        feature_importance = feature_importance['Feature']\n",
    "        \n",
    "    return feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d4890f-ee11-4821-a7d9-215f5184c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hex(x):\n",
    "    color_hex = matplotlib.colors.to_hex(x)\n",
    "    return color_hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47eb073-1e31-434b-b66a-364b03b23abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_column_iqr(data, feature, scale=1.5):\n",
    "\n",
    "    '''\n",
    "    Add nominative (1/0) column '{feature}_is_out' in DataFrame, that indicates outliers for Feature\n",
    "    '''\n",
    "\n",
    "    df = data.copy()\n",
    "\n",
    "    q1 = df[feature].quantile(0.25)\n",
    "    q3 = df[feature].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_boundary = q1 - scale*iqr\n",
    "    upper_boundary = q3 + scale*iqr\n",
    "    condition = ((df[feature] < lower_boundary) |\n",
    "                 (df[feature] > upper_boundary))\n",
    "    df[feature+'_is_out'] = condition.astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5760a-ea0c-46b0-9b31-fb87a510b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_w_target(data, target):\n",
    "\n",
    "    '''\n",
    "    Create sorted DataFrame with correlations to Target \n",
    "    '''\n",
    "    \n",
    "    df = (data\n",
    "          .corr()[target]\n",
    "          .sort_values(ascending=False, key=abs)[1:]\n",
    "          .to_frame())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ae1ca-8027-4532-8a30-b41861e7e67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_columns_match(data):\n",
    "\n",
    "    '''\n",
    "    Check if all columns in DataFrame are equla and return no equal if not\n",
    "    '''\n",
    "\n",
    "    df = data.copy()\n",
    "    df['is_equal'] = df.eq(df.iloc[:, 0], axis=0).all(1).astype(int)\n",
    "    equal_sum = df['is_equal'].sum()\n",
    "\n",
    "    if equal_sum == len(df):\n",
    "        print('All values matched')\n",
    "        return None\n",
    "    else:\n",
    "        loc = df['is_equal'] == 0, df.columns != 'is_equal'\n",
    "        result = df.loc[loc].copy()\n",
    "        return result      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34584dab-bdb2-4f15-8e4a-0055a0742d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_na(data, features_list):\n",
    "\n",
    "    '''\n",
    "    Fill all NaNs in DataFrame by 'NA'\n",
    "    '''\n",
    "\n",
    "    df = data.copy()\n",
    "    for feature in features_list:\n",
    "        df[feature] = df[feature].fillna('NA')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6570ec2-9397-4969-8ed9-d31e138f2565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_equal(data1, data2):\n",
    "\n",
    "    if data1.equals(data2):\n",
    "        print('Equal')\n",
    "    else:\n",
    "        # display rows with differences\n",
    "        data1[~data1.apply(tuple, 1).isin(data2.apply(tuple, 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24eeb0-fe36-4c3a-a6c4-38f722e97e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicated_whitespaces(x):\n",
    "\n",
    "    '''\n",
    "    Remove duplicated whitespaces in x (String variable)\n",
    "    '''\n",
    "    \n",
    "    return str.join(' ', str(x).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca26e14-bfff-4504-b177-cf9c112bbc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_dict(x, replace_dict):\n",
    "\n",
    "    '''\n",
    "    In argument 'x' replaces all replace_dict keys by replace_dict values\n",
    "    '''\n",
    "    \n",
    "    for key in replace_dict.keys():\n",
    "        x = x.replace(key, replace_dict[key])\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e742d98c-b865-4829-a6f3-7929a9d8908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_cutted_rows(data, start, end):\n",
    "    '''\n",
    "    Cut n=='start' rows at the beginning of DataFrame and \n",
    "    n=='end' rows at the end of DataFrame \n",
    "    '''\n",
    "    if end == 0:\n",
    "        slice_ = (slice(start, None), slice(None, None))\n",
    "    else:\n",
    "        # create slice, that cut rows and stay all columns\n",
    "        slice_ = (slice(start, -end), slice(None, None))\n",
    "    # unpack slice_ in .iloc\n",
    "    df = data.iloc[*slice_].copy()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b06ab9-322e-4019-aa45-c38ac33a7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_row_to_first(data):\n",
    "\n",
    "    '''\n",
    "    Make the last row of DataFrame to be the first\n",
    "    '''\n",
    "\n",
    "    df = data.copy()\n",
    "    # extract last row with 'Год' from 'pci_month'\n",
    "    first_row = df.iloc[-1].to_frame().T\n",
    "    # add it as first row to 'pci_month'\n",
    "    df = pd.concat([first_row, df], axis=0)\n",
    "    # remove last row from 'pci_month'\n",
    "    df = df.iloc[:-1].copy()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2cad83-38b0-465f-8c57-e670deecefc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_index(array, value):\n",
    "    '''\n",
    "    Returns index of Value which is in Array\n",
    "    '''\n",
    "    return np.where(array == value)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d7a78-4e04-4843-a9c7-bd08e8391459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_by_first(data, return_type='df'):\n",
    "\n",
    "    '''\n",
    "    Normalize kind: \n",
    "        first_value == first_value\n",
    "        second_value = second_value / first_value\n",
    "        third_value = third_value / first_value\n",
    "    '''\n",
    "    \n",
    "    first_value = data[0]\n",
    "    \n",
    "    data_new = [(x/first_value) for x in data]\n",
    "\n",
    "    if return_type == 'df':\n",
    "        df = pd.DataFrame(data=data_new, index=data.index)\n",
    "        return df\n",
    "    if return_type == 'series':\n",
    "        series = pd.Series(data=data_new, index=data.index)\n",
    "        return series\n",
    "    elif return_type == 'array':\n",
    "        array = np.array(data_new)\n",
    "        return array\n",
    "    elif return_type == 'list':\n",
    "        lst = list(data_new)\n",
    "        return lst\n",
    "    else:\n",
    "        print(\"'return_type' must be 'df', 'series', 'array', 'list'\")\n",
    "    \n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d2a7af-fcf4-41a0-ac7d-fbaf04bd47bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized(data, reshape=True, return_type='df'):\n",
    "\n",
    "    '''\n",
    "    MinMaxScaler 0/1 \n",
    "    '''\n",
    "    \n",
    "    if (isinstance(data, pd.Series) | \n",
    "        isinstance(data, pd.DataFrame)):\n",
    "        idxs = data.index.copy()\n",
    "    if reshape:\n",
    "        data = np.array(data).reshape(-1, 1)\n",
    "    data_new = MinMaxScaler().fit_transform(data)\n",
    "    if return_type == 'df':\n",
    "        data_new = pd.DataFrame(data=data_new, index=idxs)\n",
    "    elif return_type == 'array':\n",
    "        pass\n",
    "    else:\n",
    "        print(\"return_type must be 'df' or 'array'\")\n",
    "        return None\n",
    "        \n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0dc5ce-3863-4a0f-832e-b3f6a639b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_date(x, kind='%B %Y', translate=False):\n",
    "    '''\n",
    "    String to Date\n",
    "    '''\n",
    "    months_list = [\n",
    "        'январь', 'февраль', 'март', 'апрель', 'май', 'июнь', 'июль',\n",
    "        'август', 'сентябрь', 'октябрь', 'ноябрь', 'декабрь',\n",
    "        'Январь', 'Февраль', 'Март', 'Апрель', 'Май', 'Июнь', 'Июль',\n",
    "        'Август', 'Сентябрь', 'Октябрь', 'Ноябрь', 'Декабрь'\n",
    "    ]\n",
    "    # if months in Russian\n",
    "    if translate:\n",
    "        # split string to list\n",
    "        x = x.split()\n",
    "        # for every element in list\n",
    "        for i in x:\n",
    "            # if element is month\n",
    "            if i in months_list:\n",
    "                # find its index\n",
    "                i_index = x.index(i)\n",
    "                # translate element and access new value with it\n",
    "                new_value = months_translate(i, kind='rus-eng', capitalize=True)\n",
    "                # change old month to new one\n",
    "                x[i_index] = new_value\n",
    "        # join all elements of list to one string\n",
    "        x = ' '.join(x)\n",
    "    # transform string to date\n",
    "    x = dt.datetime.strptime(x, kind)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e1a56-4874-40e9-ae3b-e5b303fd82f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def months_translate(x, kind='rus-eng', add_year=None, capitalize=True):\n",
    "\n",
    "    '''\n",
    "    Transform russian month name to english\n",
    "    'январь' --> 'January'\n",
    "    \n",
    "    if add_year==2021: 'январь' --> 'January 2021'\n",
    "    if capitalize==False: 'январь' --> 'january'\n",
    "    '''\n",
    "    \n",
    "    # lowercase data\n",
    "    x_old = x.lower()\n",
    "    # create repalce dict\n",
    "    if kind == 'rus-eng':\n",
    "        repalce_dict = {\n",
    "            'январь': 'january',\n",
    "            'февраль': 'february',\n",
    "            'март': 'march',\n",
    "            'апрель': 'april',\n",
    "            'май': 'may',\n",
    "            'июнь': 'june',\n",
    "            'июль': 'july',\n",
    "            'август': 'august',\n",
    "            'сентябрь': 'september',\n",
    "            'октябрь': 'october',\n",
    "            'ноябрь': 'november',\n",
    "            'декабрь': 'december'\n",
    "        }\n",
    "    elif kind == 'eng-rus':\n",
    "        repalce_dict = {\n",
    "            'january': 'январь',\n",
    "            'february': 'февраль',\n",
    "            'march': 'март',\n",
    "            'april': 'апрель',\n",
    "            'may': 'май',\n",
    "            'june': 'июнь',\n",
    "            'july': 'июль',\n",
    "            'august': 'август',\n",
    "            'september': 'сентябрь',\n",
    "            'october': 'октябрь',\n",
    "            'november': 'ноябрь',\n",
    "            'december': 'декабрь'\n",
    "        }\n",
    "    else:\n",
    "        print(\"'kind' must be 'rus-eng' or 'eng-rus'\")\n",
    "    # for all keys and values in dict, replace x by value if x and key are equal\n",
    "    for k, v in repalce_dict.items():\n",
    "        if x_old == k:\n",
    "            x_new = v\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    if capitalize:\n",
    "        x_new = x_new.capitalize()\n",
    "\n",
    "    if add_year is not None:\n",
    "        x_new = x_new + ' ' + str(add_year)\n",
    "\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d39032a-7176-4e65-a803-7c2b435dba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis_new_year(\n",
    "        months=[1, 4, 7, 10],\n",
    "        month_format='%b',\n",
    "        year_format='%Y',\n",
    "        add_year_axis=True,\n",
    "        year_axis_pad=-0.105,\n",
    "        language='eng',\n",
    "        months_as_minor=False,\n",
    "        months_pad=5,\n",
    "        capitalize=True,\n",
    "        ax=None):\n",
    "\n",
    "    '''\n",
    "    /// IMPORTANT: If use language=='rus' then use set_location('EN') after plt.show() or reset_location=True\n",
    "        if current ax is last in figure, \n",
    "        because axis_new_year() function changes location to 'ru_RU'\n",
    "\n",
    "    /// Also, 'language' argument, that've set in last ax, aplied to all axes of plot.  \n",
    "    \n",
    "    Modificate date format of plots from datetime (for example, '2021-01-01') to:\n",
    "    \n",
    "    ---|-------|----- ... ---|--------|-------\n",
    "      Jan     Feb           Dec      Jan      \n",
    "      2021                           2022         \n",
    "    '''\n",
    "    \n",
    "    # set ax\n",
    "    if ax is None: ax = plt.gca()\n",
    "\n",
    "    # specify 1st month for major ticks and other months for minor ticks\n",
    "    if months_as_minor:\n",
    "        # minor months - all except 1\n",
    "        months_minor = list(filter(lambda i: i != 1, months))\n",
    "        months_major = 1\n",
    "        loc_month_minor = mdates.MonthLocator(bymonth=months_minor)\n",
    "    else:\n",
    "        months_major = months\n",
    "\n",
    "    # major ticks\n",
    "    loc_month_major = mdates.MonthLocator(bymonth=months_major)\n",
    "    # set format of months labels\n",
    "    fmt_month = mdates.DateFormatter(month_format)\n",
    "    # major ticks every year\n",
    "    loc_year = mdates.YearLocator()\n",
    "    # set format of year labels\n",
    "    fmt_year = mdates.DateFormatter(year_format)\n",
    "    \n",
    "    # set month major ticks\n",
    "    ax.xaxis.set_major_locator(loc_month_major)\n",
    "    ax.xaxis.set_major_formatter(fmt_month)\n",
    "    # set month minor ticks if necessary\n",
    "    if months_as_minor:\n",
    "        ax.xaxis.set_minor_locator(loc_month_minor)\n",
    "        ax.xaxis.set_minor_formatter(fmt_month)\n",
    "        ax.tick_params(axis='x', which='minor', pad=months_pad)\n",
    "\n",
    "    # set secondary axis with major ticks as year\n",
    "    if add_year_axis:\n",
    "        second_xaxis = ax.secondary_xaxis(year_axis_pad)\n",
    "        second_xaxis.xaxis.set_major_locator(loc_year)\n",
    "        second_xaxis.xaxis.set_major_formatter(fmt_year)\n",
    "\n",
    "    # hide the second x-axis spines and ticks\n",
    "    second_xaxis.spines['bottom'].set_visible(False)\n",
    "    second_xaxis.tick_params(bottom=False)\n",
    "\n",
    "    # translate months if necessary\n",
    "    if language=='eng':\n",
    "        locale.setlocale(locale.LC_ALL,'en_US')\n",
    "    elif language=='rus':\n",
    "        locale.setlocale(locale.LC_ALL,'ru_RU.UTF-8')\n",
    "    else:\n",
    "        print(\"'language' have to be 'eng' or 'rus'\")\n",
    "\n",
    "    # capialize months if necessary\n",
    "    if capitalize:\n",
    "        function = lambda x,pos: mdates.DateFormatter(month_format)(x,pos).capitalize()\n",
    "        ax.xaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(function))\n",
    "        ax.xaxis.set_minor_formatter(matplotlib.ticker.FuncFormatter(function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b7a3d-4aad-493e-a6cf-f89326e09339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_location(loc='EN'):\n",
    "    if loc=='EN':\n",
    "        locale.setlocale(locale.LC_ALL,'en_US')\n",
    "    elif loc=='RU':\n",
    "        locale.setlocale(locale.LC_ALL,'ru_RU.UTF-8')\n",
    "    else:\n",
    "        print(\"Location have to be 'EN' or 'RU'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ee5ce2-2287-423a-8214-350178d6e900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_axis(\n",
    "        ax=None, x_offset=10, y_offset=10, ticks_width=1, axis_width=1,\n",
    "        ticks_color='0.9', label_color='0.5', axis_color=None, **kwargs):\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    ax.tick_params(width=ticks_width, colors=ticks_color, labelcolor=label_color)\n",
    "\n",
    "    ax.spines['bottom'].set_position(('outward', x_offset))\n",
    "    ax.spines['left'].set_position(('outward', y_offset))\n",
    "\n",
    "    ax.spines['bottom'].set_linewidth(axis_width)\n",
    "    ax.spines['left'].set_linewidth(axis_width)\n",
    "\n",
    "    if axis_color is not None:\n",
    "        ax.spines['bottom'].set_color(axis_color)\n",
    "        ax.spines['left'].set_color(axis_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a56a5-1e74-4061-8075-5b9244f7a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outward_axis(ax=None, x_offset=5, y_offset=5):\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    ax.spines['bottom'].set_position(('outward', x_offset))\n",
    "    ax.spines['left'].set_position(('outward', y_offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725f6ef-d8c1-436b-b1b7-4e8e4b8ede25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis_rstyle(\n",
    "        yticks: list | None = None,\n",
    "        xticks: list | None = None,\n",
    "        yslice: list | None = None,\n",
    "        xslice: list | None = None,\n",
    "        ylim: list | None = None,\n",
    "        xlim: list | None = None,\n",
    "        x_spine_lim: list | None = None,\n",
    "        x_axis_hide: bool = False,\n",
    "        y_spine_lim: list | None = None,\n",
    "        y_axis_hide: bool = False,\n",
    "        offset_left: float = 5,\n",
    "        offset_bottom: float = 10,\n",
    "        ticks_pad_left: float = 6,\n",
    "        ticks_pad_bottom: float = 6,\n",
    "        linewidth: float = 0.75,\n",
    "        margin: bool = True,\n",
    "        customize_colors: bool = True,\n",
    "        spines_color: str ='#AAAAAA',\n",
    "        ticks_color: str ='#AAAAAA',\n",
    "        ticklabels_color: str ='#808080',\n",
    "        grid: bool = False,\n",
    "        ax=None):\n",
    "    \n",
    "    '''\n",
    "    xticks: tuple (x_min, x_max, step)\n",
    "    yticks: tuple (y_min, y_max, step)\n",
    "\n",
    "    Dependencies: \n",
    "        import: collections\n",
    "        functions: arange\n",
    "    '''\n",
    "    \n",
    "    if ax is None: ax = plt.gca()\n",
    "\n",
    "    # order of steps (important):\n",
    "        # 1 - get ticks\n",
    "        # 2 - set margins if necessary\n",
    "        # 3 - manipulations with sticks\n",
    "        # 4 - update ticks\n",
    "        # 5 - spines modification\n",
    "        # 6 - set limits\n",
    "        # 7 - tick params\n",
    "        # 8 - grid\n",
    "\n",
    "    # get ticks\n",
    "    x_ticks = ax.get_xticks()\n",
    "    y_ticks = ax.get_yticks()\n",
    "\n",
    "    if margin is not None:\n",
    "        if isinstance(margin, collections.abc.Iterable):\n",
    "            ax.margins(*margin)\n",
    "        else:\n",
    "            margin = 0.01 if margin is True else margin\n",
    "            # calculate margin coefficients coeff0 and coeff1 the way\n",
    "            # margins have to be equal\n",
    "            # 1st step: find size of figure/ax -> figisize (or ax) \n",
    "            # size should be like (ax_width, ax_height)\n",
    "            # 2d step: suggest margin_x should be equals 0.025, then\n",
    "                # ax_width * margin_x = ax_height * margin_y\n",
    "                # margin_y = (margin_x * ax_width) / ax_height\n",
    "            # so, calculated by this way values of margin_x and margin_y \n",
    "            # would make both margins equal and NOT depend on figure(or ax) size\n",
    "            ax_height, ax_width = ax.bbox.height, ax.bbox.width\n",
    "            margin_y = margin * ax_width / ax_height\n",
    "            ax.margins(x=margin, y=margin_y)\n",
    "\n",
    "    # declare xticks and yticks if necessary\n",
    "    if xticks is not None:\n",
    "        # if step not specified\n",
    "        if len(xticks) == 2:\n",
    "            # define step equals default step\n",
    "            xstep = x_ticks[1] - x_ticks[0]\n",
    "            # make xticks shape (3,)\n",
    "            xticks = np.append(xticks, xstep)\n",
    "        x_ticks = arange(xticks[0], xticks[1], xticks[2], True)\n",
    "    if yticks is not None:\n",
    "        # if step not specified\n",
    "        if len(yticks) == 2:\n",
    "            # define step equals default step\n",
    "            ystep = y_ticks[1] - y_ticks[0]\n",
    "            # make yticks shape (3,)\n",
    "            yticks = np.append(yticks, ystep)\n",
    "        y_ticks = arange(yticks[0], yticks[1], yticks[2], True)\n",
    "\n",
    "    # declare xticks and yticks with slices if necessary\n",
    "    if xslice is not None:\n",
    "        xslice_ = slice(*xslice)\n",
    "        x_ticks = x_ticks[xslice_]\n",
    "    if yslice is not None:\n",
    "        yslice_ = slice(*yslice)\n",
    "        y_ticks = y_ticks[yslice_]\n",
    "\n",
    "    # update ticks\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_yticks(y_ticks)\n",
    "\n",
    "    # set limits if necessary\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim[0], xlim[1])\n",
    "        x_ticks = [x for x in x_ticks if x <= xlim[1]]\n",
    "        x_ticks = [x for x in x_ticks if x >= xlim[0]]\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim[0], ylim[1])\n",
    "        y_ticks = [y for y in y_ticks if y <= ylim[1]]\n",
    "        y_ticks = [y for y in y_ticks if y >= ylim[0]]\n",
    "\n",
    "    # customize spines\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.spines['bottom'].set_bounds(x_ticks[0], x_ticks[-1])\n",
    "    ax.spines['bottom'].set_position(('outward', offset_bottom))\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['left'].set_bounds(y_ticks[0], y_ticks[-1])\n",
    "    ax.spines['left'].set_position(('outward', offset_left))\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    if x_spine_lim:\n",
    "        ax.spines['bottom'].set_bounds(x_spine_lim[0], x_spine_lim[-1])\n",
    "    if y_spine_lim:\n",
    "        ax.spines['left'].set_bounds(y_spine_lim[0], y_spine_lim[-1])\n",
    "\n",
    "    if customize_colors:\n",
    "        ax.spines['bottom'].set_color(spines_color)\n",
    "        ax.spines['left'].set_color(spines_color)\n",
    "        ax.tick_params(which='both', color=ticks_color)\n",
    "        ax.tick_params( which='both', labelcolor=ticklabels_color)\n",
    "\n",
    "    if linewidth:\n",
    "        ax.spines['bottom'].set_linewidth(linewidth)\n",
    "        ax.spines['left'].set_linewidth(linewidth)\n",
    "        ax.tick_params(which='both', width=linewidth)\n",
    "    \n",
    "    # set tick params and colors\n",
    "    ax.tick_params(\n",
    "        which='both', direction='out', bottom=True, size=3, left=True)\n",
    "    ax.tick_params(\n",
    "        axis='x', pad=ticks_pad_bottom)\n",
    "    ax.tick_params(\n",
    "        axis='y', pad=ticks_pad_left)\n",
    "\n",
    "    if x_axis_hide:\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.tick_params(bottom=False)\n",
    "    if y_axis_hide:\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.tick_params(left=False)\n",
    "\n",
    "    # grid customization (exclude grid lines at the edge of spines)\n",
    "    if grid:\n",
    "        if not isinstance(grid, bool):\n",
    "            raise TypeError (\"'grid' agrument must be Bool\")\n",
    "            \n",
    "        ax.grid(False)\n",
    "        x_ticks_ = ax.get_xticks()\n",
    "        y_ticks_ = ax.get_yticks()\n",
    "\n",
    "        for i in x_ticks_:\n",
    "            if (i == x_ticks_[0]) | (i == x_ticks_[-1]):\n",
    "                pass\n",
    "            else:\n",
    "                ax.plot(\n",
    "                    [i, i], [y_ticks_[0], y_ticks_[-1]],\n",
    "                    lw=0.5, ls=':', color='#D9D9D9')\n",
    "        for i in y_ticks_:\n",
    "            if (i == y_ticks_[0]) | (i == y_ticks_[-1]):\n",
    "                pass\n",
    "            else:\n",
    "                ax.plot(\n",
    "                    [x_ticks_[0], x_ticks_[-1]], [i, i],\n",
    "                    lw=0.5, ls=':', color='#D9D9D9')\n",
    "    else:\n",
    "        ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4194cbff-0d64-4b26-8880-0f90e4cbf99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_round(x, scale=1, error='skip'):\n",
    "    \n",
    "    '''\n",
    "    Round x if possible\n",
    "    '''\n",
    "    try:\n",
    "        return round(x, ndigits=scale)\n",
    "    except TypeError:\n",
    "        if error == 'type':\n",
    "            print(f'TypeError: {x}')\n",
    "        elif error == 'skip':\n",
    "            pass\n",
    "        else:\n",
    "            print(\"'error' must be 'type' or 'skip'\")\n",
    "            return\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dba938-721e-47a6-9345-e6bb59515ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float(x):\n",
    "    '''\n",
    "    Convert x to Float if possible\n",
    "    '''\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        print(f'ValueError: {x}')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad256c-b9e1-499e-946e-96fa929e22d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int(x, errors=False):\n",
    "    '''\n",
    "    Convert x to Int if possible\n",
    "    '''\n",
    "    try:\n",
    "        return int(x)\n",
    "    except ValueError:\n",
    "        return x\n",
    "        if errors:\n",
    "            print(f'ValueError: {x}')\n",
    "    except TypeError:\n",
    "        return x\n",
    "        if errors:\n",
    "            print(f'ValueError: {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6a7055-8b86-4815-8dc9-4fb6ac3fc208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_string(x):\n",
    "    '''\n",
    "    Convert x to String if possible\n",
    "    '''\n",
    "    try:\n",
    "        return str(x)\n",
    "    except ValueError:\n",
    "        print(f'ValueError: {x}')\n",
    "        return x\n",
    "    except TypeError:\n",
    "        print(f'ValueError: {x}')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be70f85-4080-4d6e-b195-434e7a4d8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness(df):\n",
    "\n",
    "    df = pd.DataFrame(df.skew(numeric_only=True),\n",
    "                      columns=['Skewness'],\n",
    "                      index=None)\n",
    "\n",
    "    df['Highly skewed'] = (abs(df['Skewness']) > 0.5)\n",
    "    df['abs'] = abs(df['Skewness'])\n",
    "\n",
    "    df = df.sort_values(by=['abs', 'Highly skewed'], ascending=False)\n",
    "    df = df.drop('abs', axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32990b4-3a0d-447a-abc1-6b589fbdf823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kurtosis(df):\n",
    "\n",
    "    df = pd.DataFrame(df.kurtosis(numeric_only=True),\n",
    "                      columns=['Kurtosis'],\n",
    "                      index=None)\n",
    "    df['Type'] = np.nan\n",
    "\n",
    "    df.loc[df['Kurtosis'] > 1, 'Type'] = 'Too Peaked'\n",
    "    df.loc[df['Kurtosis'] < -1, 'Type'] = 'Too Flat'\n",
    "    df.loc[(df['Kurtosis'] <= 1) & (df['Kurtosis'] >= -1), 'Type'] = 'Normal'\n",
    "    \n",
    "    df['abs'] = abs(df['Kurtosis'])\n",
    "    df = df.sort_values(by=['abs', 'Type'], ascending=False)\n",
    "    df = df.drop('abs', axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e7112c-67fe-40d5-93a3-0c2acd0ac14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_none(x):\n",
    "    if x is not None:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75bccc-1e6c-41e8-80ab-ace622786694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis_add_xaxis(\n",
    "        labels,\n",
    "        offset_first_axis=30,\n",
    "        offset_others=15,\n",
    "        labelsize=7,\n",
    "        labelcolor='#808080',\n",
    "        sepoffset=None,\n",
    "        sepwidth=0.5,\n",
    "        seplength=10,\n",
    "        sepcolor='#AAAAAA',\n",
    "        ax=None):\n",
    "\n",
    "    if ax is None: ax = plt.gca()\n",
    "\n",
    "    ax_xticks = ax.get_xticks()\n",
    "    ax_xticks_length = len(ax_xticks)\n",
    "    ax_xticks_min, ax_xticks_max = ax_xticks[0], ax_xticks[-1]\n",
    "    ax_xticks_lim = ax.get_xlim()\n",
    "    ax.tick_params(axis='x', labelcolor=labelcolor, labelsize=labelsize)\n",
    "\n",
    "    for i, l in enumerate(labels):\n",
    "\n",
    "        # add spaces between labels\n",
    "        if len(l) < len(ax_xticks):\n",
    "            len_corrected = (2*len(l)-1) + 2\n",
    "            l = list_add_after_every(l, ' ', 1)\n",
    "            l = [''] + l\n",
    "        else:\n",
    "            len_corrected = len(l)\n",
    "        \n",
    "        t = np.linspace(ax_xticks_min, ax_xticks_max, len_corrected)\n",
    "\n",
    "        ax_labels = ax.secondary_xaxis('bottom')\n",
    "        ax_labels.set_xticks(ticks=t, labels=l)\n",
    "        ax_labels.spines['bottom'].set_visible(False)\n",
    "        ax_labels.spines['bottom'].set_position(('outward', offset_first_axis))\n",
    "        ax_labels.tick_params(\n",
    "            axis='x', bottom=False, labelcolor=labelcolor, labelsize=labelsize)\n",
    "\n",
    "        # ax for separator lines\n",
    "        ax_sep = ax.secondary_xaxis('bottom')\n",
    "        ax_sep.set_xticks(ticks=t)\n",
    "        ax_sep.spines['bottom'].set_visible(False)\n",
    "        ax_sep_offset = sepoffset or 2.5\n",
    "        ax_sep.spines['bottom'].set_position(('outward', offset_first_axis+offset_others-ax_sep_offset))\n",
    "        ax_sep.tick_params(\n",
    "            axis='x', width=sepwidth, length=seplength,\n",
    "            labelbottom=False,\n",
    "            color=sepcolor, labelcolor=labelcolor)\n",
    "\n",
    "        # hide every second tick (not count first and last)\n",
    "        for i in ax_sep.xaxis.get_major_ticks()[1:-1][::2]:\n",
    "            i.set_visible(False)\n",
    "        ax_sep.xaxis.get_major_ticks()[0].set_visible(False)\n",
    "        ax_sep.xaxis.get_major_ticks()[-1].set_visible(False)\n",
    "\n",
    "        offset_first_axis += offset_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f73e9b-ab18-42c6-8590-4b15d9cb5eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_column_after(data, column_to_move, column_insert_after):\n",
    "\n",
    "    '''\n",
    "    Moves 'column_to_move' from its position to the position after 'column_insert_after'\n",
    "\n",
    "    Before:\n",
    "     col1 | column_insert_after | col2 | col3 | col4 | column_to_move | col5\n",
    "    -------------------------------------------------------------------------\n",
    "    \n",
    "    After:\n",
    "     col1 | column_insert_after | column_to_move | col2 | col3 | col4 | col5\n",
    "    -------------------------------------------------------------------------\n",
    "    '''\n",
    "\n",
    "    df = data.copy()\n",
    "    \n",
    "    col = df.pop(column_to_move)\n",
    "    idx = df.columns.get_loc(column_insert_after) + 1\n",
    "    df.insert(idx, column_to_move, col)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1bbb5e-9733-4ea0-8f72-c8e2b67d1d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_describe(data):\n",
    "    \n",
    "    df = data.copy()\n",
    "    # varibles types\n",
    "    dtypes = df.dtypes.rename('Type').to_frame()\n",
    "    # frequency\n",
    "    frequency = df.count().rename('Count').to_frame()\n",
    "    # unique values\n",
    "    unique = df.nunique().rename('Unique').to_frame()\n",
    "    # NaNs\n",
    "    nans = df.isnull().sum().rename('NaN').to_frame()\n",
    "    # NaNs fraction\n",
    "    nans_frac = df.isnull().mean().round(2)\n",
    "    nans_frac = nans_frac.rename('Percentages').to_frame()\n",
    "    # list with results\n",
    "    results_list = [dtypes, frequency, unique, nans, nans_frac]\n",
    "    # df with results\n",
    "    results = pd.concat(results_list, axis=1)\n",
    "    results['Percentages'] = (results['Percentages'] * 100).astype('int64')\n",
    "    results = results.sort_values(['NaN'], ascending=False)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c076a49-e506-4151-a194-e1770088847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gridplot(\n",
    "        data, features, target=None, figsize=None, ncols=3, kind='reg',\n",
    "        plot_shape='rectangle', markersize=15, hscale=1, pscale=1, regplot_kwargs={},\n",
    "        pointplot_kwargs={}, scatterplot_kwargs={}, histplot_kwargs={}):\n",
    "\n",
    "    nrows = math.ceil(len(features) / ncols)\n",
    "    nplots = np.arange(1, len(features)+1)\n",
    "\n",
    "    if plot_shape == 'square':\n",
    "        whscale=(2,2)\n",
    "    if plot_shape == 'rectangle':\n",
    "        whscale=(4,2.5)\n",
    "\n",
    "    if figsize is not None:\n",
    "        figsize = figsize\n",
    "    else:\n",
    "        width = whscale[0] * ncols\n",
    "        height = whscale[1] * nrows\n",
    "        figsize_width = width * pscale\n",
    "        figsize_height = height * pscale\n",
    "        figsize = (figsize_width, figsize_height)\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    if kind == 'reg':\n",
    "        for feature, plot in zip(features, nplots):\n",
    "            plt.subplot(nrows, ncols, plot)\n",
    "            sns.regplot(\n",
    "                data=data,\n",
    "                x=feature,\n",
    "                y=target,\n",
    "                scatter_kws={\n",
    "                    'ec': '#606060',\n",
    "                    's': markersize,\n",
    "                    'alpha': 0.9\n",
    "                },\n",
    "                **regplot_kwargs\n",
    "            )\n",
    "            plt.ylabel(None)\n",
    "\n",
    "    if kind == 'point':\n",
    "        for feature, plot in zip(features, nplots):\n",
    "            plt.subplot(nrows, ncols, plot)\n",
    "            sns.pointplot(\n",
    "                data=data,\n",
    "                x=feature,\n",
    "                y=target,\n",
    "                markersize=markersize,\n",
    "                linestyle='none',\n",
    "                capsize=0.031,\n",
    "                err_kws={'lw': 0.81*pscale},\n",
    "                **pointplot_kwargs\n",
    "            )\n",
    "            plt.ylabel(None)\n",
    "            plt.xticks(rotation=45)\n",
    "\n",
    "    if kind == 'hist':\n",
    "        for feature, plot in zip(features, nplots):\n",
    "            plt.subplot(nrows, ncols, plot)\n",
    "            sns.histplot(\n",
    "                data=data,\n",
    "                x=feature,\n",
    "                alpha=0.95,\n",
    "                **histplot_kwargs\n",
    "            )\n",
    "            plt.ylabel(None)\n",
    "\n",
    "    if kind == 'scatter':\n",
    "        for feature, plot in zip(features, nplots):\n",
    "            plt.subplot(nrows, ncols, plot)\n",
    "            sns.scatterplot(\n",
    "                data=data,\n",
    "                x=feature,\n",
    "                y=target,\n",
    "                s=markersize,\n",
    "                **scatter_kwargs\n",
    "            )\n",
    "            plt.ylabel(None)\n",
    "        \n",
    "    plt.subplots_adjust(hspace=0.4*hscale)\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd0857-1c53-4821-a5a7-07afda6f439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def legend_inline(\n",
    "        ncols=None,\n",
    "        loc='lower left',\n",
    "        bbox_to_anchor=(0,1),\n",
    "        frameon=False,\n",
    "        ax=None):\n",
    "\n",
    "    if ax is None: ax = plt.gca()\n",
    "    ncols_fact = len(ax.get_legend_handles_labels()[0])\n",
    "\n",
    "    ncols = ncols or ncols_fact or 6\n",
    "\n",
    "    params = {\n",
    "        'ncols': ncols,\n",
    "        'loc': loc,\n",
    "        'bbox_to_anchor': bbox_to_anchor,\n",
    "        'frameon': frameon\n",
    "    }\n",
    "    \n",
    "    return params\n",
    "\n",
    "def legend_mid(\n",
    "        frameon=False,\n",
    "        loc='upper left',\n",
    "        bbox_to_anchor=(1,1),\n",
    "        markersize=1,\n",
    "        labelspacing=0.5,\n",
    "        alignment='left'\n",
    "):\n",
    "\n",
    "    params = {\n",
    "        'frameon': frameon,\n",
    "        'loc': loc,\n",
    "        'bbox_to_anchor': bbox_to_anchor,\n",
    "        'markerscale': markersize,\n",
    "        'alignment': alignment,\n",
    "        'labelspacing': labelspacing,\n",
    "    }\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "85ea862a-431b-47fc-bb86-9677fa5f7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_detrending_differences(data, add_nan=True):\n",
    "\n",
    "    arr = np.asarray(data)\n",
    "\n",
    "    if add_nan:\n",
    "        result = [np.NaN]\n",
    "    else:\n",
    "        result = []\n",
    "    \n",
    "    for i in range(1, len(arr)):\n",
    "        val = arr[i] - arr[i - 1]\n",
    "        result.append(val)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "85e55bde-01ce-4467-8edf-be62f30856cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_scatterplot_matrix(\n",
    "        x,\n",
    "        y=None,\n",
    "        lags=12,\n",
    "        ncols=3,\n",
    "        s=10,\n",
    "        figsize=(10, 5),\n",
    "        figtitle=None,\n",
    "        lowess=False,\n",
    "        return_fig=False,\n",
    "        constrained_layout=True):\n",
    "\n",
    "    if y is None:\n",
    "        first_lag = 1\n",
    "        nrows = math.ceil(len(arange(lags))/ncols)\n",
    "        remove_axs = nrows*ncols - len(arange(lags))\n",
    "    else:\n",
    "        first_lag = 0\n",
    "        nrows = math.ceil(len(arange(lags, True))/ncols)\n",
    "        remove_axs = nrows*ncols - len(arange(lags, True))\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        nrows, ncols, figsize=figsize, constrained_layout=constrained_layout)\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    for i in arange(first_lag, lags, True):\n",
    "        x_shift = np.roll(x, i, axis=0)[i:]\n",
    "        if y is None:\n",
    "            x_ = x[i:].copy()\n",
    "        else:\n",
    "            x_ = y[i:].copy()\n",
    "        corr = scipy.stats.pearsonr(x_shift, x_)[0]\n",
    "        corr = str(round(corr, 4))\n",
    "        ax[idx].scatter(x_shift, x_, s=s)\n",
    "        # title\n",
    "        ax[idx].set_title(f'Lag: {i}', pad=10)\n",
    "        \n",
    "        # correlation coefficient\n",
    "        ax[idx].annotate(\n",
    "            corr, xy=(0.9, 0.9), xycoords='axes fraction', size=9,\n",
    "            bbox=dict(\n",
    "                facecolor='#FEFEFE', edgecolor=palette[0], lw=0.25,\n",
    "                boxstyle='square'))\n",
    "        \n",
    "        # calculate smooth with LOWESS\n",
    "        if lowess:\n",
    "            lowess = statsmodels.nonparametric.smoothers_lowess.lowess\n",
    "            lowess_line = lowess(x_, x_shift, return_sorted=True)\n",
    "            ax[idx].plot(\n",
    "                lowess_line[:, 0], lowess_line[:, 1],\n",
    "                lw=2, color=palette[1])\n",
    "\n",
    "        idx +=1\n",
    "\n",
    "    if remove_axs != 0:\n",
    "        # remove unnecessary plots\n",
    "        for i in arange(remove_axs, 0, -1):\n",
    "            fig.delaxes(ax[-i])\n",
    "\n",
    "    if constrained_layout is False:\n",
    "        plt.subplots_adjust(wspace=0.3, hspace=0.5)\n",
    "        y_adj = 0.95\n",
    "    else:\n",
    "        y_adj = None\n",
    "\n",
    "    if figtitle is not None:\n",
    "        fig.suptitle(figtitle, y=y_adj)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if return_fig:\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cab1a5-02dd-4db6-86e1-822a16fec518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acf(\n",
    "        acf_w_alphas=None, data=None, lags=40, partial=False, scatter=False, s=2,\n",
    "        transparency_lines=1, color_lines=None, exclude_first=True,\n",
    "        transparency_significant=0.15, color_significant=None, **kwargs):\n",
    "\n",
    "    if acf_w_alphas is None:\n",
    "        acf_w_alphas = ts_acf_calculate(data, lags=lags, partial=partial, **kwargs) \n",
    "        \n",
    "    acf = acf_w_alphas[:, 0]\n",
    "    alphas = acf_w_alphas[:, 1:]\n",
    "    \n",
    "    lags = len(acf)\n",
    "    xticks = arange(lags)\n",
    "    color_palette = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "    color_significant = color_significant or color_palette[2]\n",
    "    color_lines = color_lines or color_palette[0]\n",
    "\n",
    "    if exclude_first:\n",
    "        acf[0] = 0\n",
    "        alphas[:1] = 0\n",
    "\n",
    "    if scatter:\n",
    "        plt.scatter(\n",
    "            x=xticks,\n",
    "            y=acf,\n",
    "            s=s\n",
    "        )\n",
    "    for i in arange(lags):\n",
    "        plt.plot(\n",
    "            [i, i],\n",
    "            [0, acf[i]],\n",
    "            color=color_lines,\n",
    "            alpha=transparency_lines\n",
    "        )\n",
    "    if exclude_first:\n",
    "        plt.fill_between(\n",
    "            arange(lags)[1:],\n",
    "            (alphas[:, 0] - acf)[1:],\n",
    "            (alphas[:, 1] - acf)[1:],\n",
    "            lw=0,\n",
    "            color=color_significant,\n",
    "            alpha=transparency_significant\n",
    "        )\n",
    "    else:\n",
    "        plt.fill_between(\n",
    "            arange(lags),\n",
    "            alphas[:, 0] - acf,\n",
    "            alphas[:, 1] - acf,\n",
    "            lw=0,\n",
    "            color=color_significant,\n",
    "            alpha=transparency_significant\n",
    "        )\n",
    "\n",
    "    plt.plot([-1, lags], [0, 0])\n",
    "    plt.gca().spines[['bottom', 'left']].set_visible(False)\n",
    "    plt.grid(False)\n",
    "    plt.xlim(-2, lags+1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe95b9-1ca8-45fc-bd55-5c503018ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_acf_calculate(data, lags=36, alpha=0.05, partial=False, **kwargs):\n",
    "\n",
    "    if partial:\n",
    "        acf_result = statsmodels.tsa.stattools.pacf(\n",
    "            data, nlags=lags, alpha=alpha, method='ywadjusted', **kwargs)\n",
    "    else:\n",
    "        acf_result = statsmodels.tsa.stattools.acf(\n",
    "            data, nlags=lags, alpha=alpha, missing='none', **kwargs)\n",
    "\n",
    "    acf = acf_result[0]\n",
    "    alphas = acf_result[1]\n",
    "    result = np.hstack([acf.reshape(-1,1), alphas])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca3faf-29f9-4c8e-b8b5-e5436dc0d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_acf_last_significant_index(data, lags=36, partial=False):\n",
    "    '''\n",
    "    Return index of first insignificant element in ACF or PACF\n",
    "\n",
    "    Attributes:\n",
    "        ci - confident intervals for ACF value (example, result[1] of statsmodels.tsa.stattools.acf)\n",
    "    '''\n",
    "    acf = ts_acf_calculate(data, lags=lags, partial=partial)\n",
    "    ci = acf[:, 1:]\n",
    "    \n",
    "    for i, j in enumerate(ci):\n",
    "        status = np.all(j > 0) if j[0] > 0 else np.all(j < 0)\n",
    "        if not status:\n",
    "            break\n",
    "    return i-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a57fc8c5-d3bc-406a-b6f4-58535cbaba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ax_current():\n",
    "    return plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05305449-8cdd-4856-b4e5-2f7dcef4efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def legend_create_handles(\n",
    "        n=None,\n",
    "        kind='line',\n",
    "        labels=True,\n",
    "        colors=None,\n",
    "        alpha=1,\n",
    "        markersize=3):\n",
    "\n",
    "    if n is None:\n",
    "        n = len(ax_current().get_legend_handles_labels()[0])\n",
    "    if colors is None:\n",
    "        colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    \n",
    "    handles = []\n",
    "\n",
    "    if kind == 'line':\n",
    "        marker = None\n",
    "        markersize = None\n",
    "        linestyle = '-'\n",
    "        alpha = alpha\n",
    "    elif kind == 'rect':\n",
    "        marker = 's'\n",
    "        markersize = markersize\n",
    "        linestyle = 'None'\n",
    "        alpha = alpha\n",
    "    elif kind == 'point':\n",
    "        marker = 'o'\n",
    "        markersize = markersize\n",
    "        linestyle = 'None'\n",
    "        alpha = alpha\n",
    "    else:\n",
    "        print(\"'kind' must be 'line', 'rect' or 'point'\")\n",
    "\n",
    "    for i, (v, c) in enumerate(zip(arange(n), colors)):\n",
    "        handles.append(\n",
    "            Line2D(\n",
    "                [], [], marker=marker, markersize=markersize,\n",
    "                linestyle=linestyle, lw=1.5, color=c, alpha=alpha),\n",
    "        )\n",
    "\n",
    "    result = dict(handles=handles)\n",
    "    \n",
    "    if (kind == 'rect') | ((kind == 'point')):\n",
    "        result['handletextpad'] = 0\n",
    "\n",
    "    if labels:\n",
    "        if labels is True:\n",
    "            labels = ax_current().get_legend_handles_labels()[1]\n",
    "        else:\n",
    "            pass\n",
    "        result['labels'] = labels\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7d4c68f-1727-4317-84c9-25ee4225ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis_adjust_barplot(\n",
    "        axis='x',\n",
    "        line_hidden=False,\n",
    "        labelsize=9,\n",
    "        labelcolor='#606060',\n",
    "        weight='bold', \n",
    "        pad=-5,\n",
    "        ax=None,\n",
    "        **kwargs):\n",
    "    \n",
    "    if ax is None: ax = plt.gca()\n",
    "        \n",
    "    if axis == 'x':\n",
    "        ax.spines['bottom'].set_bounds(\n",
    "            ax.patches[0].get_x(),\n",
    "            ax.patches[-1].get_x() + ax.patches[-1].get_width())\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), weight=weight)\n",
    "\n",
    "        if line_hidden:\n",
    "            ax.spines['bottom'].set_visible(False)\n",
    "            ax.tick_params(axis='x', bottom=False)\n",
    "        \n",
    "    if axis == 'y':\n",
    "        ax.spines['left'].set_bounds(\n",
    "            ax.patches[0].get_y(),\n",
    "            ax.patches[-1].get_y() + ax.patches[-1].get_height())\n",
    "        ax.set_yticklabels(ax.get_yticks(), weight=weight)\n",
    "\n",
    "        if line_hidden:\n",
    "            ax.spines['left'].set_visible(False)\n",
    "            ax.tick_params(axis='y', left=False)\n",
    "\n",
    "    ax.tick_params(\n",
    "        axis=axis, labelsize=labelsize, labelcolor=labelcolor,\n",
    "        pad=pad, **kwargs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d14dd5-f94c-4994-a860-e74bafb46456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_session(name, directory='sessions'):\n",
    "    if directory != 'sessions':\n",
    "        directory = f'sessions/{directory}/'\n",
    "    else:\n",
    "        directory = 'sessions/'\n",
    "    # check if dir exists and create it if not\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "    # save session\n",
    "    dill.dump_session(directory+name)\n",
    "\n",
    "\n",
    "def load_session(name, directory='sessions'):\n",
    "    if directory != 'sessions':\n",
    "        directory = f'sessions/{dir}/'\n",
    "    else:\n",
    "        directory = 'sessions/'\n",
    "    # load session\n",
    "    dill.load_session(directory+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782dd470-72c9-4507-afec-0e325c394ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_LLR(m1, m2, df=1):\n",
    "\n",
    "    '''\n",
    "    Dependencies:\n",
    "        - from scipy.stats import chi2\n",
    "    '''\n",
    "    \n",
    "    l1 = m1.llf\n",
    "    l2 = m2.llf\n",
    "    lr = (2*(l2-l1))\n",
    "    p = chi2.sf(lr, df).round(3)\n",
    "    \n",
    "    return print(f'p-value: {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4f58625d-da16-4c3d-964f-fdc57617c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_by_minutes(data, feature, first_month):\n",
    "\n",
    "    df = data.copy()\n",
    "    \n",
    "    df_agg = (df\n",
    "              .groupby(by=['month', 'day', 'hour', 'minute'], as_index=False)\n",
    "              .agg({feature:'median'}))\n",
    "    \n",
    "    new_feature = (df\n",
    "         .reset_index()\n",
    "         .merge(df_agg,\n",
    "             on=['month', 'day', 'hour', 'minute'], how='left',\n",
    "             suffixes=('', '_by_minutes'))\n",
    "         .set_index('index', drop=True)).asfreq('10min')[feature+'_by_minutes'].copy()\n",
    "\n",
    "    len_values_of_the_first_month = len(df.loc[first_month])\n",
    "    new_feature = new_feature.shift(len_values_of_the_first_month).copy()\n",
    "    new_feature.index.name = None\n",
    "\n",
    "    return new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127fd141-b029-49da-b807-88e63a7d0577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_column_to_index(data, column, format=None, **kwargs):\n",
    "    df = data.copy()\n",
    "    df[column] = pd.to_datetime(df[column], format=format, **kwargs)\n",
    "    df = df.set_index(column)\n",
    "    df.index.name = None\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7db18d-846f-4a90-b0ba-be7c1e9742c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_arima_forecast(model, steps, data, exog=None, ci=[80, 95]):\n",
    "\n",
    "    df = data.copy()\n",
    "    results = model.get_forecast(steps=steps, exog=exog)\n",
    "\n",
    "    forecasts = pd.DataFrame(\n",
    "        index = pd.date_range(\n",
    "            df.index[0], results.predicted_mean.index[-1], freq=df.index.freq),\n",
    "        data=pd.concat([\n",
    "            df.iloc[:, 0], results.predicted_mean], axis=0),\n",
    "        columns=['data'])\n",
    "\n",
    "    forecasts['is_forecast'] = np.where(\n",
    "        forecasts.index.date < results.predicted_mean.index[0].date(), 0, 1)\n",
    "\n",
    "    for ci_value in ci:\n",
    "        alpha = (100 - ci_value) / 100\n",
    "        forecasts[f'lower_ci{ci_value}'] = \\\n",
    "            results.conf_int(alpha=alpha).iloc[:, 0]\n",
    "        forecasts[f'upper_ci{ci_value}'] = \\\n",
    "            results.conf_int(alpha=alpha).iloc[:, 1]\n",
    "\n",
    "    return forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "09393d1d-f81c-4853-8e53-847411f16350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_plot_arima_forecast(\n",
    "        forecasts=None, model=None, steps=100, data=None,\n",
    "        exog=None, ci=[80, 95], alpha_ci1=0.2, alpha_ci2=0.1):\n",
    "\n",
    "    if model is not None:\n",
    "        forecasts = ts_arima_forecast(model, steps=steps, data=data, exog=exog, ci=[80, 95])\n",
    "\n",
    "    plt.plot(\n",
    "    forecasts[forecasts['is_forecast']==0]['data'])\n",
    "    \n",
    "    plt.plot(\n",
    "        forecasts[forecasts['is_forecast']==1]['data'],\n",
    "        color=saturate_color(palette[2], 1.5),\n",
    "        label='Forecast')\n",
    "    \n",
    "    plt.fill_between(\n",
    "        x=forecasts[forecasts['is_forecast']==1].index,\n",
    "        y1=forecasts[forecasts['is_forecast']==1]['lower_ci80'],\n",
    "        y2=forecasts[forecasts['is_forecast']==1]['upper_ci80'],\n",
    "        lw=0,\n",
    "        color=palette[2],\n",
    "        alpha=alpha_ci1,\n",
    "        label='Level 80%')\n",
    "    \n",
    "    plt.fill_between(\n",
    "        x=forecasts[forecasts['is_forecast']==1].index,\n",
    "        y1=forecasts[forecasts['is_forecast']==1]['lower_ci95'],\n",
    "        y2=forecasts[forecasts['is_forecast']==1]['upper_ci95'],\n",
    "        lw=0,\n",
    "        color=palette[2],\n",
    "        alpha=alpha_ci2,\n",
    "        label='Level 95%')\n",
    "    \n",
    "    plt.legend(**legend_inline(), labelspacing=0.75);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957dbc3-3b26-4c77-961d-1adc7cc7f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_arima_fourier_create_exog(y, period1=144, period2=72, order1=9, order2=9):\n",
    "    \n",
    "    fourier_s1 = statsmodels.tsa.deterministic.Fourier(period1, order1)\n",
    "    fourier_s1_y = fourier_s1.in_sample(y.index)\n",
    "    fourier_s2 = statsmodels.tsa.deterministic.Fourier(period2, order2)\n",
    "    fourier_s2_y = fourier_s2.in_sample(y.index)\n",
    "    fourier_s12_y = pd.concat([fourier_s1_y, fourier_s2_y], axis=1)\n",
    "    \n",
    "    return fourier_s12_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "c441db7a-dcf8-4624-b987-42f2d5722905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split_indexes(data, start, train_size, test_size, size_unit, n_splits, freq):\n",
    "\n",
    "    '''\n",
    "    Sliding window TS-split\n",
    "    '''\n",
    "    \n",
    "    df = data.copy()\n",
    "\n",
    "    train_window = {size_unit: train_size}\n",
    "    train_offset = pd.offsets.DateOffset(**train_window)\n",
    "\n",
    "    if isinstance(start, str):\n",
    "        start_date = pd.to_datetime(start) - train_offset\n",
    "    else:\n",
    "        start_date = start - train_offset\n",
    "\n",
    "    train_indexes_list = []\n",
    "    test_indexes_list = []\n",
    "\n",
    "    for n in arange(n_splits):\n",
    "        \n",
    "        train_window = {size_unit: train_size}\n",
    "        train_offset = pd.offsets.DateOffset(**train_window)\n",
    "        train_start = start_date\n",
    "        train_end = train_start + train_offset\n",
    "        train_indexes = pd.date_range(train_start, train_end, freq=freq)[:-1]\n",
    "        train_indexes_list.append(train_indexes)\n",
    "        \n",
    "        test_window = {size_unit: test_size}\n",
    "        test_offset = pd.offsets.DateOffset(**test_window)\n",
    "        test_start = start_date + train_offset\n",
    "        test_end = test_start + test_offset\n",
    "        test_indexes = pd.date_range(test_start, test_end, freq=freq)[:-1]\n",
    "        test_indexes_list.append(test_indexes)\n",
    "\n",
    "        start_date = start_date + test_offset\n",
    "\n",
    "    return train_indexes_list, test_indexes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "50347fd2-7acf-4681-b5ca-b6efff0aa3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model_evaluation(\n",
    "        data, start, train_size, test_size, size_unit, n_splits, freq,\n",
    "        orders, fourier_periods, fourier_orders, exog_variables=None):\n",
    "\n",
    "    time_start = time.time()\n",
    "    \n",
    "    train_indexes, test_indexes = cv_split_indexes(\n",
    "        data, start, train_size, test_size, size_unit, n_splits, freq)\n",
    "\n",
    "    if len(train_indexes) != len(test_indexes):\n",
    "        print('ERROR')\n",
    "\n",
    "    results = {}\n",
    "    results_ = {}\n",
    "    models = {}\n",
    "    models_names = {}\n",
    "\n",
    "    for split_number in arange(len(train_indexes)):\n",
    "        \n",
    "        train_data = data.loc[train_indexes[split_number]]\n",
    "        test_data = data.loc[test_indexes[split_number]]\n",
    "        \n",
    "        if exog_variables is not None:\n",
    "            exog_variables_train = exog_variables.loc[train_indexes[split_number]]\n",
    "            exog_variables_test = exog_variables.loc[test_indexes[split_number]]\n",
    "\n",
    "        for order in orders:\n",
    "            for fourier_period in fourier_periods:\n",
    "                for fourier_order in itertools.product(fourier_orders, repeat=len(fourier_period)):\n",
    "\n",
    "                    # create df with fourier exogs for train dataset\n",
    "                    exogs_df_train = pd.DataFrame()\n",
    "                    # create df with fourier exogs for test dataset\n",
    "                    exogs_df_test = pd.DataFrame()\n",
    "                    for p, k in zip(fourier_period, fourier_order):\n",
    "\n",
    "                        fourier_train = statsmodels.tsa.deterministic.Fourier(p, k)\n",
    "                        exogs_train = fourier_train.in_sample(train_data.index)\n",
    "                        exogs_df_train = exogs_train.join(exogs_df_train)\n",
    "\n",
    "                        fourier_test = statsmodels.tsa.deterministic.Fourier(p, k)\n",
    "                        exogs_test = fourier_test.in_sample(test_data.index)\n",
    "                        exogs_df_test = exogs_test.join(exogs_df_test)\n",
    "\n",
    "                    if exog_variables is not None:\n",
    "                        exogs_df_train = exogs_df_train.join(exog_variables_train)\n",
    "                        exogs_df_test = exogs_df_test.join(exog_variables_test)\n",
    "                    \n",
    "                    # fit model\n",
    "                    model = SARIMAX(\n",
    "                        train_data, exog=exogs_df_train,\n",
    "                        order=order,\n",
    "                        seasonal_order=(0, 0, 0, 0),\n",
    "                    ).fit(maxiter=1000, disp=False)\n",
    "\n",
    "                    # calculate steps for forecast\n",
    "                    steps = len(test_data)\n",
    "                    # get forecast\n",
    "                    forecast = model.get_forecast(steps=steps, exog=exogs_df_test)\n",
    "                    # y_pred\n",
    "                    y_pred = forecast.predicted_mean\n",
    "                    # y_test\n",
    "                    y_test = test_data\n",
    "                    # RMSE\n",
    "                    rmse = root_mean_squared_log_error(y_pred, y_test)\n",
    "\n",
    "                    k_list = list(fourier_order)\n",
    "\n",
    "                    model_name = (tuple(order), list(fourier_period), list(fourier_order))\n",
    "                    model_name_str = f'{tuple(order)}, {list(fourier_period)}, {list(fourier_order)}'\n",
    "\n",
    "                    models_names[model_name_str] = model_name\n",
    "                    \n",
    "                    if model_name_str in results:\n",
    "                        results[model_name_str] = np.append(results[model_name_str], rmse)\n",
    "                    else:\n",
    "                        results[model_name_str] = np.array([rmse])\n",
    "\n",
    "    # change models in 'result' by 'modelN'-type names and create separate models list\n",
    "    for (i, key), m in zip(enumerate(results.keys()), models_names.keys()):\n",
    "        # models[f'model{i}'] = key\n",
    "        models[f'model{i}'] = models_names[m]\n",
    "        results_[f'model{i}'] = results[key]\n",
    "\n",
    "    results_full = {}\n",
    "    results_full['models'] = models\n",
    "    results_full['splits'] = results_\n",
    "    \n",
    "    clear_output()\n",
    "    \n",
    "    time_finish = time.time() - time_start\n",
    "    time_finish = dt.timedelta(seconds=np.round(time_finish))\n",
    "\n",
    "    print(f'Execution time: {time_finish}')\n",
    "\n",
    "    return results_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399efd50-072e-455e-8997-92a8c825ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_add_after_every(lst, element, add_every):\n",
    "    # using [item for subgroup in groups for item in subgroup]\n",
    "    lst_new = [\n",
    "        x for y in (lst[i:i+add_every] + [element] * (i < len(lst) - add_every + 1) \n",
    "                    for i in range(0, len(lst), add_every)) for x in y\n",
    "    ]\n",
    "    return lst_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "194c1547-fe1a-4d40-b0c5-8c35a0ffcab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis_remove_xaxis(ax=None):\n",
    "\n",
    "    if ax is None: ax = plt.gca()\n",
    "\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(bottom=False, labelbottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8695c492-f324-4218-882d-79c4bd83b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_weekly_data(start):\n",
    "\n",
    "    # range_ = pd.date_range(start=start, periods=1, freq='W')\n",
    "    # end = dt.datetime.strftime(range_.date[0], '%Y-%m-%d')\n",
    "\n",
    "    start_dt = dt.datetime.strptime(start, '%Y-%m-%d')\n",
    "    end_dt = start_dt + dt.timedelta(days=6)\n",
    "    end = dt.datetime.strftime(end_dt, '%Y-%m-%d')\n",
    "\n",
    "    return slice(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "id": "82c69139-0693-4679-87b4-7246acc51199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_with_fourier(order, fourier_period, fourier_order, train_data, exog=None):\n",
    "\n",
    "    exogs_df_train = \\\n",
    "        ts_arima_fourier_get_exogs(fourier_period, fourier_order, train_data)\n",
    "\n",
    "    if exog is not None:\n",
    "        exogs_df_train = exogs_df_train.join(exog)\n",
    "\n",
    "    # fit model\n",
    "    model = SARIMAX(\n",
    "        train_data, exog=exogs_df_train,\n",
    "        order=order,\n",
    "        seasonal_order=(0, 0, 0, 0),\n",
    "    ).fit(maxiter=1000, disp=False)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "id": "e171bb0e-cde7-4991-b158-ae9c69bc14e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_arima_fourier_get_exogs(fourier_period, fourier_order, train_data, test_data=None):\n",
    "\n",
    "    # create df with fourier exogs for train dataset\n",
    "    exogs_df_train = pd.DataFrame()\n",
    "    # create df with fourier exogs for test dataset\n",
    "    exogs_df_test = pd.DataFrame()\n",
    "    \n",
    "    for p, k in zip(fourier_period, fourier_order):\n",
    "\n",
    "        fourier_train = statsmodels.tsa.deterministic.Fourier(p, k)\n",
    "        exogs_train = fourier_train.in_sample(train_data.index)\n",
    "        exogs_df_train = exogs_train.join(exogs_df_train)\n",
    "\n",
    "        if test_data is not None:\n",
    "            fourier_test = statsmodels.tsa.deterministic.Fourier(p, k)\n",
    "            exogs_test = fourier_test.in_sample(test_data.index)\n",
    "            exogs_df_test = exogs_test.join(exogs_df_test)\n",
    "\n",
    "    if test_data is not None:\n",
    "        return exogs_df_train, exogs_df_test\n",
    "    else:\n",
    "        return exogs_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "id": "256ab4b5-6239-4800-910f-1d5ac85a65e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekly_rmse(data, start, exog=None, periods=4):\n",
    "\n",
    "    rmse_lst = []\n",
    "    for i in arange(periods):\n",
    "        \n",
    "        train_august_start = data.loc[start].index[0] - dt.timedelta(weeks=2)\n",
    "        train_august_end = train_august_start + dt.timedelta(days=14) - dt.timedelta(minutes=10)\n",
    "        train_august = data.loc[train_august_start:train_august_end, 'target1'].copy()\n",
    "    \n",
    "        test_august_start = data.loc[start].index[0]\n",
    "        test_august_end = data.loc[start].index[0] + dt.timedelta(weeks=1) - dt.timedelta(minutes=10)\n",
    "        test_august = data.loc[test_august_start:test_august_end, 'target1'].copy()\n",
    "    \n",
    "        model = fit_model_with_fourier(\n",
    "            (1,1,2), [144], [4], train_data=train_august, exog=exog)\n",
    "    \n",
    "        train_exogs, test_exogs = ts_arima_fourier_get_exogs(\n",
    "            fourier_period=fourier_period,\n",
    "            fourier_order=fourier_order,\n",
    "            train_data=train_data,\n",
    "            test_data=test_data)\n",
    "\n",
    "        if exog is not None:\n",
    "            train_exogs = train_exogs.join(exog)\n",
    "            test_exogs = test_exogs.join(exog)\n",
    "            \n",
    "        forecast = model.get_forecast(steps=len(test_august), exog=test_exogs)\n",
    "        rmse = root_mean_squared_log_error(forecast.predicted_mean, test_august)\n",
    "        rmse_lst.append(rmse)\n",
    "\n",
    "        start_dt = dt.datetime.strptime(start, '%Y-%m-%d') + dt.timedelta(days=7)\n",
    "        start = dt.datetime.strftime(start_dt, '%Y-%m-%d')\n",
    "        print(start)\n",
    "\n",
    "    return rmse_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "id": "f3061ede-406c-4036-9b74-6c57a2a0ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_model_forecasts(\n",
    "        order, fourier_period, fourier_order,\n",
    "        data=None, exog=None, start=None, end=None, periods=None):\n",
    "\n",
    "    '''\n",
    "    Data - before two weeks since forecast start\n",
    "    '''\n",
    "\n",
    "    start_dt = dt.datetime.strptime(start, '%Y-%m-%d')\n",
    "    end_dt = dt.datetime.strptime(end, '%Y-%m-%d')\n",
    "    train_start_dt = start_dt - dt.timedelta(weeks=2)\n",
    "    \n",
    "    forecasts = pd.DataFrame(\n",
    "        columns=['forecast', 'lower80', 'upper80', 'lower95', 'upper95'])\n",
    "\n",
    "    for i in arange(periods):\n",
    "\n",
    "        train_start = dt.datetime.strftime(train_start_dt, '%Y-%m-%d')\n",
    "        train_end_dt = train_start_dt + dt.timedelta(weeks=2) - dt.timedelta(minutes=10)\n",
    "        train_end = dt.datetime.strftime(train_end_dt, '%Y-%m-%d')\n",
    "        \n",
    "        test_start_dt = train_start_dt + dt.timedelta(weeks=2)\n",
    "        test_end_dt = test_start_dt + dt.timedelta(weeks=1) - dt.timedelta(minutes=10)\n",
    "        test_start = dt.datetime.strftime(test_start_dt, '%Y-%m-%d')\n",
    "        test_end = dt.datetime.strftime(test_end_dt, '%Y-%m-%d')\n",
    "        \n",
    "        train_data = data.loc[train_start:train_end].copy()\n",
    "        test_data = data.loc[test_start:test_end].copy()\n",
    "\n",
    "        train_exogs, test_exogs = ts_arima_fourier_get_exogs(\n",
    "            fourier_period=fourier_period,\n",
    "            fourier_order=fourier_order,\n",
    "            train_data=train_data,\n",
    "            test_data=test_data)\n",
    "\n",
    "        if exog is not None:\n",
    "            # train_exogs = train_exogs.join(exog)\n",
    "            test_exogs = test_exogs.join(exog)\n",
    "\n",
    "        model = fit_model_with_fourier(\n",
    "            order, fourier_period, fourier_order, train_data=train_data, exog=exog)\n",
    "        \n",
    "        forecast = model.get_forecast(steps=len(test_data), exog=test_exogs)\n",
    "\n",
    "        y_pred = forecast.predicted_mean\n",
    "        ci80 = forecast.conf_int(alpha=0.2)\n",
    "        ci95 = forecast.conf_int(alpha=0.05)\n",
    "        lower80 = ci80.iloc[:, 0].copy()\n",
    "        upper80 = ci80.iloc[:, 1].copy()\n",
    "        lower95 = ci95.iloc[:, 0].copy()\n",
    "        upper95 = ci95.iloc[:, 1].copy()\n",
    "\n",
    "        forecast_df = pd.DataFrame(\n",
    "            index=['forecast', 'lower80', 'upper80', 'lower95', 'upper95'],\n",
    "            columns=test_data.index,\n",
    "            data = [y_pred, lower80, upper80, lower95, upper95])\n",
    "\n",
    "        forecast_df = forecast_df.T\n",
    "\n",
    "        if not len(forecasts):\n",
    "            forecasts = forecast_df\n",
    "        else:\n",
    "            forecasts = pd.concat([forecasts, forecast_df], axis=0)\n",
    "\n",
    "        train_start_dt += dt.timedelta(weeks=1)\n",
    "\n",
    "    return forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e9c59-fbe6-4a71-8e1f-79e5b4d2a4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0a3340-9b84-469a-b87c-7332392b223b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "electric-power-consumption",
   "language": "python",
   "name": "electric-power-consumption"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
